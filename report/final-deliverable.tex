\section{Final BNF}\label{sec:final-bnf}

\input{final-bnf}

\section{Final GUI}\label{sec:final-gui}

\subsection{Code Editor}\label{subsec:code-editor}

\subsection{Notebook View}\label{subsec:notebook-view}

\subsection{Plot View}\label{subsec:plot-view}

\section{Notable Features}\label{sec:notable-features}
\input{notable-features}

\section{Lexer}\label{sec:lexer}

Initial lexer design was based on a simple regular expression based lexer, but this was later replaced with a more
functional approach using pattern matching on the input string.
The reason for this change was that the regular expression based lexer was difficult to extend and maintain due to 
the lack of type safety.
For example if we had a more general regex called before a more specific one, the more general one would always match
first, even if the more specific one should have matched.

This was solved by using a more functional approach, where the type system of F\# would inform us if a case would 
never be matched due to the order of the cases or otherwise, preventing a class of easily overlooked errors during development.
The lexer is now implemented as a recursive pattern matching function that takes a string and returns a list of 
tokens, complete with their lexeme and position in the input string.

Lexer errors are also accumulated in a list of type \textit{LexerError}, which are displayed to the user in the GUI\@.

Something of note is that the lexer parses numbers itself, rather than passing them to the parser as strings.

Additionally, due to the permittance of user defined operators, the lexer makes special considerations when lexing 
special characters, as the distinction between a built-in operator (with precedence) and a user defined operator (
currently without taking precedence into account) is made during lexing.

Furthermore, both block comments (\textit{/* */}) and line comments (\textit{//}) are handled by the lexer by ignoring
the contents of the comment.
In future, it may be interesting represent comments as a token in the AST, allowing for systems such as documentation
generation or automatic formatting to be implemented.

\section{Parser}\label{sec:parser}

The parser is implemented using Pratt parsing\citep{pratt1973top}, which is a top-down operator precedence parsing 
method that allows for easy extension and modification of the grammar.
It works by assigning a precedence to each token, as well as functions specifying how to parse the token when 
encountering it in a prefix, infix or postfix position.

For example, take the expression $2 + 3 * 4$.

The parser would first encounter the number \textit{2}, which has a precedence of 0 and a prefix function that
simply returns the number.
Thus, the current state of the parser is $2$.
The parser would then encounter the operator \textit{+}, which has a precedence of 1 and a left associative infix
function that takes the left hand side and the right hand side and returns a binary expression node.
The parser then attempts to parse the right hand side of the operator with a precendence level higher than the
plus operator, as Pratt parsing must ensure that higher precedence operations (such as multiplication) are parsed
first.
The parser would then encounter the number \textit{3}, which again is treated as a literal and returned.
The parser then encounters the operator \textit{*}, which has a precedence of 2 (higher than the plus operator) and 
as such the parser cannot yet resolve the \textit{+} operator; it must handle the higher precedence multiplication
operator first.
The parser saves the left hand side (the number 3) and then parses the right hand side of the multiplication 
operator using a precedence level higher than the multiplication operator.
It encounters the number \textit{4}, which is returned as a literal.
The parser then returns the binary expression node for the multiplication operator, with the left hand side being
the number 3 and the right hand side being the number 4.
The parser then returns to the plus operator, which can now be resolved as the left hand side is the number 2 and the
right hand side is the result of the multiplication operator.

This is a simple example, but Pratt parsing can handle more complex expressions with ease, such as nested
expressions and function calls.

Using Pratt parsing has improved the extensibility of the parser, as adding new operators or changing the grammar
is as simple as adding a new case to the parser.

A slight limitation is during ambiguity, such as the \textit{(} symbol, which can be used for a grouping, a lambda 
definition, a tuple or a \textit{unit} type when encountered in the prefix position.
This is resolved through a state machine approach, where the parser can move around the state at will, allowing 
lookahead and backtracking in order to reach a point where the ambiguity is resolved.

In order to simplify the Virtual Machine\ref{sec:virtual-machine}, the parser parses all binary and unary operations 
as function calls, with the operator as the function name.

In order to make type inference simpler for operators that are overloaded for both unary and binary operations (such 
as the \textit{-} operator), the operator itself keeps track of the manner in which it is called (unary or binary) and
returns the appropriate AST node. 
This allows for easier type inference (as the names of the overloaded functions are different), 
and simplifies the bytecode generation process by removing ambiguity in the AST\@.
This idea could possibly be extended to allow other overloaded function names (with varying numbers of arguments or 
arguments of different types).

Error handling in the parser is done through the use of the monadic \textit{ParserResult} type, which can either 
return a successful result or an error message, which is then displayed to the user in the GUI allowing for clear 
and easy diagnosis of errors.

\section{AST}\label{sec:expression}

The AST of the language is represented as a list of statements, where a statement is either expression, a
variable assignment or another statement type.
It is typed (after type inference\ref{sec:type-inference}) in order to allow for easier optimisation and
bytecode generation.

The AST representation is given in section~\ref{sec:final-bnf}.

\section{Type Inference}\label{sec:type-inference}
\input{type-inference}

\section{Optimisation}\label{sec:optimisation}

Before compilation, the AST is optimised by removing dead code and constant folding.

\subsection{Dead code elimination}\label{subsec:dead-code-elimination}

Dead code elimination is performed on the AST by removing any statements that are not used.
For example, if a variable is declared but never used, the variable declaration is removed or if an expression is
written but never used, the expression is removed.

This is accomplished by through static analysis of the AST, where the following process is repeated until no more dead
code can be removed:

\begin{algorithmic}
    \While{Dead code can be removed}
        \For{Each node in the AST}
            \If{Node is a statement}
                \If{Statement is not used}
                    \State Remove statement
                \EndIf
            \ElsIf{Node is an expression}
                \If{Expression is not used}
                    \State Remove expression
                \EndIf
            \ElsIf{Node is a binding}
                \If{Variable is not used}
                    \State Remove binding
                \EndIf
            \EndIf
        \EndFor
    \EndWhile
\end{algorithmic}

The process is repeated until no more dead code can be removed, allowing for long chains of dead code to be 
removed (for example if a variable is used in a function that is never called, the function would first be removed
and then the variable).
It is to be noted that variable assignments are never removed during DCE when running the code editor due to the 
attached REPL, as the user may wish to use the variable in the REPL\@, or when running code blocks in the notebook 
view\ref{sec:notebook-view} as the variable may be used in a later code block.
However, DCE can be aggressively performed when transpiling to C\ref{sec:transpiler}, as the user is not expected to 
interact with the generated C code.

\subsection{Constant folding}\label{subsec:constant-folding}

Constant folding is performed on the AST by evaluating constant expressions at compile time, such as $2 + 2 \ra 4$.
This is accomplished using the initial interpreter implementation, which recursively evaluates the AST and replaces
constant expressions with their evaluated value.
Only constants are evaluated, and thus no variable resolution is performed due to the cost of this operation.

\section{Initial Design of the Bytecode Virtual Machine and Compiler}\label{sec:initial-design-of-the-bytecode-virtual-machine-and-compiler}

\input{initial-design-of-the-bytecode-virtual-machine-and-compiler}

\section{Virtual Machine}\label{sec:virtual-machine2}

The Virtual Machine (VM) was responsible for executing the compiled bytecode. 
It was designed as a stack-based machine, meaning that it used a stack to store intermediate values during computation. 
The VM's state was represented by the \texttt{VM} type, defined as follows:

\begin{minted}{fsharp}
type VM = {
    Chunk: Chunk
    IP: int
    Stack: ResizeArray<Value>
    ScopeDepth: int Â 
}
\end{minted}

\noindent where:

\begin{itemize}
    \item \texttt{Chunk} held the bytecode and associated data (constant pool, line information) currently being executed.
    \item \texttt{IP} (Instruction Pointer) was an integer representing the index of the next bytecode instruction
    \item \texttt{Stack} was a dynamically sized array used to store values during computation.
    Operations like arithmetic, comparisons, and function calls would push and pop values from this stack.
    \item \texttt{ScopeDepth} tracked the current level of scope nesting.
\end{itemize}

The \texttt{createVM} function initialized a new VM instance with a given chunk.
The core of the VM was the \texttt{run} function, a recursive loop that fetched, decoded, and executed instructions until a \texttt{RETURN} instruction was encountered or an error occurred.

Key helper functions included:

\begin{itemize}
    \item \texttt{push} and \texttt{pop} for manipulating the stack
    \item \texttt{peek} for inspecting the top value on the stack without removing it
    \item \texttt{readByte} for reading the next byte from the bytecode and incrementing the IP
    \item \texttt{readConstant} and \texttt{readConstantLong} for reading constant values from the constant pool
    \item \texttt{call} for calling functions, which involved setting up a new frame on the call stack
\end{itemize}

The \texttt{run} function used a match expression to dispatch to the appropriate code based on the current opcode.
Each opcode case handled a specific instruction, potentially manipulating the stack, performing calculations, or managing control flow.

The \texttt{interpret} function provided the main entry point for executing a chunk of bytecode.
It first disassembled the chunk for debugging purposes, then created a new VM instance and called \texttt{run} to start the execution process.

In conclusion, this initial design established a solid foundation for a stack-based virtual machine and its associated compiler.
It emphasized a clean separation of concerns between compiling and executing code, a compact bytecode representation, and a focus on essential features for a functional language. The inclusion of debugging tools, a well-defined error-handling mechanism, and a dedicated virtual machine for execution further contributed to the robustness and efficiency of the system.

\section{Virtual Machine}\label{sec:virtual-machine}

\section{Prelude}\label{sec:prelude}

A prelude is implicitly included in every program, which contains some useful functions defined in the language, as 
well as wrappers for the built-in functions of the Virtual Machine, such as \textit{cos}, \textit{log}, etc.

Notable functions include:

\begin{itemize}
    \item \textit{map}, \textit{fold} and \textit{filter} functions for lists.
    \item \textit{range} function for generating a list of numbers.
    \item \textit{sqrt}, \textit{cubeRoot} which are specialisations of the \textit{root} function.
    \item \textit{head}, \textit{tail} and \textit{len} functions for lists.
    \item \textit{findIntegral} function for finding the integral of a function.
\end{itemize}

We felt it was useful implementing these in-language functions as it allows for more concise and readable code, as
well as showcasing the power of the language.

\section{Plotting}\label{sec:plotting}

The plotting system is implemented using ScottPlot\citep{scottPlot}, a plotting library for .NET\@.

The functionality is exposed to the user through 3 built-in functions: \textit{plot}, \textit{plotFunc} and 
\textit{plotFuncs}.

\paragraph{\textit{plot}} takes in a record of configuration options of the following type:

\begin{minted}{fsharp}
    type PlotConfig = {
        title: string,
        x: [float],
        y: [float],
        ptype: "bar" | "scatter" | "signal",
    }
\end{minted}

The resulting plot is then displayed in a separate window based on these configuration options.

Here are some examples of the \textit{plot} function in use:

\begin{minted}{fsharp}
let x = [1..10] : [float]
let y = map(x, (x) -> x^2)
let data = {
    title = "Example Plot",
    XValues = x,
    YValues = y,
    ptype = "scatter"
}
plot(data)
\end{minted}

Image~\ref{fig:scatter-plot} shows the resulting plot.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{scatterPlot}
    \caption{Scatter plot}\label{fig:scatter-plot}
\end{figure}

The \textit{ptype} option allows for the user to specify the type of plot, with the options being \textit{bar},
\textit{scatter} and \textit{signal}.

The \textit{bar} type is useful for visualising data, the \textit{scatter} type is useful for plotting functions and
the \textit{signal} type is useful for plotting signals.
An example of a bar plot is shown in image~\ref{fig:bar-plot}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{barChart}
    \caption{Bar plot}\label{fig:bar-plot}
\end{figure}

\paragraph{The \textit{plotFunc}} function takes in a string title and a pure function of type \textit{float -> float}.
The function is then plotted on the graph with an infinite range of x values.
Optionally, the user can also specify two more float values, \textit{start} and \textit{end}, in which case the 
integral of the function is calculated and displayed on the graph.

For example, given the following snippet:

\begin{minted}{fsharp}
let polynomial = (x) -> x^2 + 2.0 * x + 1.0
plotFunc("Polynomial", polynomial)
\end{minted}

Image~\ref{fig:polynomial-plot} shows the resulting plot.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{polynomialPlot}
    \caption{Polynomial plot}\label{fig:polynomial-plot}
\end{figure}

\paragraph{The \textit{plotFuncs}} function takes in a string title and a list of pure functions of type 
\textit{float -> float}.
This allows for multiple plots to be placed on the same window, which we felt was valuable for comparing functions 
or plotting derivatives.

For example, given the following snippet:

\begin{minted}{fsharp}
let polynomial = (x) -> x^2 + 2.0 * x + 1.0
let derivate = differentiate(polynomial) // find the derivative of the polynomial
let integrand = integrate(polynomial) // find the integral of the polynomial
let tangentFunc = tangentFunc(polynomial, 2.0) // find the tangent function at x = 2.0

plotFuncs("Polynomial", [polynomial, derivate, integrand, tangentFunc])
\end{minted}

Image~\ref{fig:multiple-plots} shows the resulting plot.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{multiplePlots}
    \caption{Multiple plots}\label{fig:multiple-plots}
\end{figure}

The plots are very interactive, with the user being able to zoom in and out, move around and adjust the axes as
desired.

The plot windows also have an input at the bottom, which allows for the user to input a function and have it plotted
on command\ref{fig:plot-input}.
This is useful for quick visualisation of functions, and allows for a more interactive experience.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{plotInput}
    \caption{Plot input}\label{fig:plot-input}
\end{figure}

\section{Drawing}\label{sec:drawing}

As well as plotting, the user also has the option of drawing arbitrary shapes on a canvas, and attaching event 
listeners to them.
This is done by means of the \textit{draw} function, which takes in a record of configuration options of the following
type:

\begin{minted}{fsharp}
    type DrawConfig = {
        x: float,
        y: float,
        width: float,
        height: float,
        color: string,
        shape: "rectangle" | "circle",
        trace?: bool, 
    }
\end{minted}

Or a list of the above record type, allowing for multiple shapes to be drawn on the same canvas.

The \textit{draw} function then returns a unique identifier for the shape, which can be used to attach event 
listeners, allowing for movement of the shape through key presses.

The following example attached event listeners to a shape which moves it left and right following the \textit{cos} curve:

\begin{minted}{fsharp}
on(id, Keys.Right, (state) -> { x = state.x + 10.0, y = cos(state.x) * 10.0 + 100.0 })
on(id, Keys.Left, (state) -> { x = state.x - 10.0, y = cos(state.x) * 10.0 + 100.0 })
\end{minted}

Where keys is a record defined in the prelude of the language (see~\autoref{sec:prelude}).

Additionally, the \textit{trace} option allows for the shape to leave a trail behind it, which can be useful for
animations or visualising movement.

\todo{Add images of drawings}

\section{Notebook View}\label{sec:notebook-view}

The notebook view is a feature that allows the user to write code in a more interactive way, similar to Jupyter
notebooks\citep{Jupyter}.

\section{Transpiler}\label{sec:transpiler}

The user also has the option of transpiling their code to C, which can then be compiled and run as a standalone
executable, allowing for faster execution of the code which is important for larger or more computationally
intensive programs.

\section{Code architecture}\label{sec:code-architecture}